{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "poza-MusicVAE",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOoaHdhhIat4RB695dlh4X9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f5d5a5e24d374a07bf07f99f9d003ade": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e7403a799dfa47838ae1e9b1872253b8",
              "IPY_MODEL_6017b73ec95447679622688ebc96acea",
              "IPY_MODEL_300f3e7d72ca4bca8bbda20ef9268690"
            ],
            "layout": "IPY_MODEL_102f9fcf15b34b019881fc63f83c3d74"
          }
        },
        "e7403a799dfa47838ae1e9b1872253b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bcc23fb9bbe341209d787a8e7cb8c25a",
            "placeholder": "​",
            "style": "IPY_MODEL_bdcc35d506a9452797480bb48b12bfe3",
            "value": ""
          }
        },
        "6017b73ec95447679622688ebc96acea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a7e4103213d344d983470536e4cfb11d",
            "max": 9912422,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_92127eb0246644e6b97bdd2e4483f393",
            "value": 9912422
          }
        },
        "300f3e7d72ca4bca8bbda20ef9268690": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_820bc15e02034cc781f4956122dccf77",
            "placeholder": "​",
            "style": "IPY_MODEL_20d3e746a01d4675ac20ef23054692e7",
            "value": " 9913344/? [00:00&lt;00:00, 23481257.16it/s]"
          }
        },
        "102f9fcf15b34b019881fc63f83c3d74": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bcc23fb9bbe341209d787a8e7cb8c25a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bdcc35d506a9452797480bb48b12bfe3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a7e4103213d344d983470536e4cfb11d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "92127eb0246644e6b97bdd2e4483f393": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "820bc15e02034cc781f4956122dccf77": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "20d3e746a01d4675ac20ef23054692e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "882a82f9f1d44db3b9b59709210b8ab7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_42bfdeef32724688a58b4277f62a96b2",
              "IPY_MODEL_1869e2e54ee74d10a8bc80c218cea868",
              "IPY_MODEL_04261721c30d4e27aae52ff39e83e3c6"
            ],
            "layout": "IPY_MODEL_8193509dd6f04e5499fa0f5b6f6deaf0"
          }
        },
        "42bfdeef32724688a58b4277f62a96b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a99726ab30a342148d64b8bcd2837a75",
            "placeholder": "​",
            "style": "IPY_MODEL_f4f76e46da1a48e5bfcc5e53adc75920",
            "value": ""
          }
        },
        "1869e2e54ee74d10a8bc80c218cea868": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_20993d8cf88f4cce850d020196fd545b",
            "max": 28881,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b58a10f4420c461fb6e5cb4535b05299",
            "value": 28881
          }
        },
        "04261721c30d4e27aae52ff39e83e3c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a877a006554d4ab1848d225ce5d2cd6b",
            "placeholder": "​",
            "style": "IPY_MODEL_8049b7fa308d4c928cac45480b63e5ed",
            "value": " 29696/? [00:00&lt;00:00, 351192.84it/s]"
          }
        },
        "8193509dd6f04e5499fa0f5b6f6deaf0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a99726ab30a342148d64b8bcd2837a75": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f4f76e46da1a48e5bfcc5e53adc75920": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "20993d8cf88f4cce850d020196fd545b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b58a10f4420c461fb6e5cb4535b05299": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a877a006554d4ab1848d225ce5d2cd6b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8049b7fa308d4c928cac45480b63e5ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "03190e4dbc9b4df68bcdcd1a49cb526f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_67d90e52600646c9b6591a63daf612ae",
              "IPY_MODEL_a146eab698e447d2ac128d179a9e7ad3",
              "IPY_MODEL_b2fb6d37f2b94233bdd08780271476ea"
            ],
            "layout": "IPY_MODEL_5f85bbc07f3a4d9da2ab0b64b3f0b3e5"
          }
        },
        "67d90e52600646c9b6591a63daf612ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0e10ac47b5b34a30a0e229b921bcc332",
            "placeholder": "​",
            "style": "IPY_MODEL_03178f89e6f74128840df24073602570",
            "value": ""
          }
        },
        "a146eab698e447d2ac128d179a9e7ad3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c99294ff22fc4bf9b132dcc188de9f60",
            "max": 1648877,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cddabab7347c41d6a1c2306a7a612a13",
            "value": 1648877
          }
        },
        "b2fb6d37f2b94233bdd08780271476ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dcfb86eeb9d04c689bf4270dfa2e7a56",
            "placeholder": "​",
            "style": "IPY_MODEL_df4b0366a88b40078e773dc111e6a801",
            "value": " 1649664/? [00:00&lt;00:00, 3554677.93it/s]"
          }
        },
        "5f85bbc07f3a4d9da2ab0b64b3f0b3e5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e10ac47b5b34a30a0e229b921bcc332": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "03178f89e6f74128840df24073602570": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c99294ff22fc4bf9b132dcc188de9f60": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cddabab7347c41d6a1c2306a7a612a13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dcfb86eeb9d04c689bf4270dfa2e7a56": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df4b0366a88b40078e773dc111e6a801": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ca4707a3f1eb4a0f8a932504ba0f52e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6bb95b80d3c743239abe414e742b4cab",
              "IPY_MODEL_e17979f29d66452f8b78869505116eb5",
              "IPY_MODEL_da4fc7f369934281987f1c7827bca7b4"
            ],
            "layout": "IPY_MODEL_a1f0cbedae8a4f418d40fe6b179a9799"
          }
        },
        "6bb95b80d3c743239abe414e742b4cab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c5cbc7a42acb483c9fe1b3aa78808297",
            "placeholder": "​",
            "style": "IPY_MODEL_868c5b2f778a44c1b239bbb6009573d2",
            "value": ""
          }
        },
        "e17979f29d66452f8b78869505116eb5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_23a7dfca1f0f417c88d4fca66b653997",
            "max": 4542,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7fc6415dad2f42d9a0021e5d860d259f",
            "value": 4542
          }
        },
        "da4fc7f369934281987f1c7827bca7b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9aa340f8c35343fd9227ae8a310d134c",
            "placeholder": "​",
            "style": "IPY_MODEL_8f285cb29c0449cda1e76713a6a3175f",
            "value": " 5120/? [00:00&lt;00:00, 61634.91it/s]"
          }
        },
        "a1f0cbedae8a4f418d40fe6b179a9799": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c5cbc7a42acb483c9fe1b3aa78808297": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "868c5b2f778a44c1b239bbb6009573d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "23a7dfca1f0f417c88d4fca66b653997": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7fc6415dad2f42d9a0021e5d860d259f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9aa340f8c35343fd9227ae8a310d134c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f285cb29c0449cda1e76713a6a3175f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sunjii/MusicVAE/blob/main/MusicVAE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "wwv2UXH0qY_q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 사전 지식 탐색 및 정리\n",
        "\n",
        "## VAE\n",
        "- VAE는 latent representation에 효과적인 모델로 입증되었음\n",
        "- AE와 형태면에서 비슷함. Bottleneck 구조를 통해 벡터를 압축하여 latent code를 생성. \n",
        "  - latent space를 통해 입력 데이터간의 유사성과 차이를 통해 학습\n",
        "  - VAE는 AE와는 달리 Generative한 모델임.\n",
        "  - 생성에 강점을 보이는 이유는 latent space가 연속되게 생성되기 때문. 반면 AE는 이산적인 분포를 가지기 때문에 데이터 재구성 단계에서 저품질의 데이터가 생기는 원인이 됨.\n",
        "  - VAE는 KL-divergence를 loss 함수로 사용함\n",
        "- KL-divergence를 통해서 VAE의 latent space 분포가 `표준 정규 분포`에 가깝도록 학습하게 됨\n",
        "\n",
        ">참고링크: https://ratsgo.github.io/generative%20model/2017/12/19/vi/\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "## VAE 한계점\n",
        "\n",
        "- sequential data에 한계점이 존재함.\n",
        "- recurrent VAE 모델들은 long-term sequence에 약함\n",
        "- 논문에서는 이러한 한계점을 극복하기 위해 `hierachical decoder`를 제안함\n",
        "  - 첫번째 output embedding이 input의 sub-sequence로 쓰임\n",
        "  - 각 embedding들은 독립적으로 sub-sequence들을 생성함\n",
        "- 이러한 구조는 모델이 latent code를 utilize하고 `posterior collapse` 문제를 회피하는데 도움이 됨\n",
        "\n",
        "  - posterior collapse: 시퀀스 모델을 VAE형태로 표현하면 global latent z를 이용하여 다양한 속성의 시퀀스를 생성할 수 있다. 하지만 이 때 decoder가 encoder의 condition을 무시하고 시퀀스를 생성하는 현상을 말함.\n",
        "\n",
        "![](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fqd1lx%2FbtqXMfe0scF%2FYRdkqrZhcInlZ2yPRchOzK%2Fimg.png)\n",
        "\n",
        "  - collapse 발생하는 이유\n",
        "    - decoder가 latent z 없이 과거 데이터만으로 충분히 생성 가능한 경우\n",
        "    - 다양한 latent z가 존재할 수 있음\n",
        "    - VAE가 local information을 선호하는 경향이 있음\n",
        "    - 학습 초기 encoder가 z를 잘 표현하지 못 해서 등등..\n",
        "    - 참고링크: https://stopspoon.tistory.com/63"
      ],
      "metadata": {
        "id": "DGSUTSA-lVWx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model\n",
        "- RNN은 recurrent한 모델이기 때문에 latent code를 무시할 수 있음\n",
        "- 전체 시퀀스를 단일 latent vector로 압축하게 되는데 따라서 long-term 시퀀스인 경우 정보의 손실일 일어날 수 있음\n",
        "- 이 같은 문제를 해결하기 위해 `hierarchical RNN`을 디코더에 적용\n",
        "\n",
        "![](https://i.imgur.com/y397wfb.png)\n",
        "\n",
        "## Bidirectional Encoder\n",
        "- 2 layer 양방향 LSTM 사용\n",
        "- input 시퀀스 x로 첫번째 state vector $ \\overrightarrow{h_{T}} $ 와 $ \\overleftarrow{h_{T}} $ 를 두번째 bi-direction LSTM layer에서 얻는다.\n",
        "- 이는 concat되어 $h_{T}$를 얻고 2개의 fully connectd layer로 들어간다.\n",
        "\n",
        "$$ \\mu = W_{h\\mu}h_{T} + b_{\\mu} $$\n",
        "\n",
        "$$ σ = log(exp(W_{hσ} + b_{σ}) + 1) $$\n",
        "\n",
        "$W_{hμ}, W_{hσ}$는 가중치 행렬이고, $b_μ, b_σ$는 bias 벡터이다. 논문에서는 2048개의 layer와 512의 latent 차원을 사용한다. 일반적인 VAE처럼 뮤와 시그마를 통해서 latent 분포를 표현할 수 있다. 양방향 recurrent encoder는 이상적으로 input 시퀀스의 long-term context를 잘 표현할 수 있다고 함.\n",
        "\n",
        "## Hierarchical Decoder\n",
        "- 단층 RNN을 사용한 경우 -> 매우 떨어지는 샘플링 및 재구성 성능을 보임\n",
        "  - 출력 시퀀스가 생성되면서 latent state의 영향력이 점차 소실되기 때문 (vanishing)\n",
        "- 이러한 문제를 해결하기 위해 계층적 RNN 구조를 디코더에 적용함\n",
        "- input 시퀀스 x를 중복되지 않는 U개의 `sub sequence` $y_u$로 나누게 되면 다음처럼 표현 할 수 있음. 여기서 $i_u$는 endpoint임\n",
        "\n",
        "$$ y_u = \\{ x_{i_u}, x_{i_u+1}, x_{i_u+2}, ..., x_{i_u+1} -1 \\} $$\n",
        "\n",
        "$$ →X = \\{ y_1, y_2, ..., y_U \\} $$\n",
        "\n",
        "- 위 식에서 $i_{U+1} = T$로 정의함. 이후 latent vector z는 fully-connetced layer를 통과하며 tanh 활성 함수를 거쳐 conductor RNN의 초기 state를 생성함.\n",
        "\n",
        "- 논문에서는 Conductor를 위해서 2개층의 양방향 LSTM (hidden state size 1024, 512 output dimension)을 사용함.\n",
        "\n",
        "### Conductor\n",
        "\n",
        "- conductor가 임베딩 벡터 c를 생성하면 각 벡터는 독립적으로 fully-connected layer를 지나면서 tanh 활성함수를 통해 RNN decoder의 최종 바닥층의 초기 state를 생성함.\n",
        "- RNN 디코더는 softmax 출력층을 거치면서 auto-regressive하게 시퀀스 분포를 생성함. 여기서 디코더는 서브시퀀스 $y_{u}$에 해당하는 분포를 생성함.\n",
        "- 디코더의 바닥층에서는 매 step마다 conductor의 임베딩 $c_u$와 이전 step의 출력 토큰을 결합하여 input으로 사용함.\n",
        "  - 이러한 계층적 구조때문에 각 서브시퀀스 $y_u$는 연결된 conductor에서 생성된 $c_u$를 통해서만 영향을 받음\n",
        "- 논문에서는 2 layer LSTM과 각 layer마다 1024 units의 decoder RNN을 사용함.\n",
        "\n",
        "### 결과\n",
        "\n",
        "- 논문에서는 실험을 통해 decoder의 scope를 제한하는 것이 latent code를 사용하는 long-term 구조 모델에 중요하다는 사실을 발견함\n",
        "- 각 서브시퀀스의 끝에서 decoder의 state가 다시 conductor로 들어가는 `auto regressive conductor`에서는 성능이 좋지 않았음.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "1XfSqa69qb0y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Implementation\n",
        "\n",
        "## Data \n",
        "\n",
        "MIDI 데이터를 학습에 사용하기 위해서 벡터로 변환하는 전처리 과정이 필요하다.\n",
        "\n",
        "[magenta](https://github.com/magenta/magenta/tree/main/magenta/models/music_vae) 를 이용하여 .mid, .midi 파일을 tfrecord 포멧으로 변환시킬 수 있다. 이후 학습에 사용하면 된다!\n",
        "\n",
        "* tfrecord: 바이너리 데이터 포멧으로 serial 데이터를 읽는데 특화되어 있다. [참고링크](https://bcho.tistory.com/1190)"
      ],
      "metadata": {
        "id": "ObGCN5xZNArV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 구글 드라이브 연결\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "\n",
        "# data dir\n",
        "DATA_DIR = '/content/drive/MyDrive/musicVAE/data'\n",
        "OUT_DIR = '/content/drive/MyDrive/musicVAE/data_out'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1TNYdPpZlVGN",
        "outputId": "d87b5967-0078-4b80-814e-358f5d1ccf2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 데이터 확인\n",
        "\n",
        "간단하게 tfds에 있는 groove 데이터를 가져와서 사용하겠습니다. 4마디 드럽 샘플을 뽑아내기 위해 4마디 데이터셋인 groove/4bar-midionly를 가져옵니다."
      ],
      "metadata": {
        "id": "FCTvxdFhGGuj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "\n",
        "groove = tfds.builder(\n",
        "    name=\"groove/4bar-midionly\", # 4마디 드럼 데이터셋을 불러옵니다.\n",
        "    )\n",
        "print(groove.info)\n",
        "print(groove.info.features['midi'])\n",
        "print(groove.info.features['drummer'].names)\n",
        "print(groove.info.features['style']['primary'].names)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZB7TZtEDgRVO",
        "outputId": "ff29d273-216e-4c31-b48d-2da38a22d77f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tfds.core.DatasetInfo(\n",
            "    name='groove',\n",
            "    version=2.0.1,\n",
            "    description='The Groove MIDI Dataset (GMD) is composed of 13.6 hours of aligned MIDI and\n",
            "(synthesized) audio of human-performed, tempo-aligned expressive drumming\n",
            "captured on a Roland TD-11 V-Drum electronic drum kit.',\n",
            "    homepage='https://g.co/magenta/groove-dataset',\n",
            "    features=FeaturesDict({\n",
            "        'bpm': tf.int32,\n",
            "        'drummer': ClassLabel(shape=(), dtype=tf.int64, num_classes=10),\n",
            "        'id': tf.string,\n",
            "        'midi': tf.string,\n",
            "        'style': FeaturesDict({\n",
            "            'primary': ClassLabel(shape=(), dtype=tf.int64, num_classes=18),\n",
            "            'secondary': tf.string,\n",
            "        }),\n",
            "        'time_signature': ClassLabel(shape=(), dtype=tf.int64, num_classes=5),\n",
            "        'type': ClassLabel(shape=(), dtype=tf.int64, num_classes=2),\n",
            "    }),\n",
            "    total_num_examples=21415,\n",
            "    splits={\n",
            "        'test': 2033,\n",
            "        'train': 17261,\n",
            "        'validation': 2121,\n",
            "    },\n",
            "    supervised_keys=None,\n",
            "    citation=\"\"\"@inproceedings{groove2019,\n",
            "        Author = {Jon Gillick and Adam Roberts and Jesse Engel and Douglas Eck and David Bamman},\n",
            "        Title = {Learning to Groove with Inverse Sequence Transformations},\n",
            "        Booktitle\t= {International Conference on Machine Learning (ICML)}\n",
            "        Year = {2019},\n",
            "    }\"\"\",\n",
            "    redistribution_info=,\n",
            ")\n",
            "\n",
            "Tensor(shape=(), dtype=tf.string)\n",
            "['drummer1', 'drummer2', 'drummer3', 'drummer4', 'drummer5', 'drummer6', 'drummer7', 'drummer8', 'drummer9', 'drummer10']\n",
            "['afrobeat', 'afrocuban', 'blues', 'country', 'dance', 'funk', 'gospel', 'highlife', 'hiphop', 'jazz', 'latin', 'middleeastern', 'neworleans', 'pop', 'punk', 'reggae', 'rock', 'soul']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.python.ops.numpy_ops import np_config\n",
        "np_config.enable_numpy_behavior()"
      ],
      "metadata": {
        "id": "13Y94NDBLhKO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the full GMD with MIDI only (no audio) as a tf.data.Dataset\n",
        "train_dataset, val_dataset, test_dataset = tfds.load(\n",
        "    name=\"groove/4bar-midionly\", # 4마디 드럼 데이터셋을 불러옵니다.\n",
        "    split=(tfds.Split.TRAIN, tfds.Split.VALIDATION, tfds.Split.TEST),\n",
        "    try_gcs=True,\n",
        "    )\n",
        "\n",
        "\n",
        "# Build your input pipeline\n",
        "train_dataset = train_dataset.shuffle(1024).batch(32).prefetch(\n",
        "    tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "val_dataset = val_dataset.shuffle(1024).batch(32).prefetch(\n",
        "    tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "test_dataset = test_dataset.shuffle(1024).batch(32).prefetch(\n",
        "    tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "print(len(train_dataset), len(val_dataset), len(test_dataset))\n",
        "for features in train_dataset.take(1):\n",
        "  # Access the features you are interested in\n",
        "  midi = features[\"midi\"]\n",
        "  print('=============')\n",
        "  print(midi.shape)\n",
        "  print(midi)\n"
      ],
      "metadata": {
        "id": "WtlSu1Sc8Psk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## VAE\n",
        "![](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fqd1lx%2FbtqXMfe0scF%2FYRdkqrZhcInlZ2yPRchOzK%2Fimg.png)\n",
        "\n",
        "- 인코더\n",
        "\n",
        "양방향 LSTM encoder 사용\n",
        "\n",
        "- 디코더\n",
        "\n",
        "단방향 LSTM decoder 사용\n",
        "\n",
        "## Hierarchical Decoder\n",
        "\n",
        "- Conductor\n",
        "\n",
        "- 논문에서 진행한 방식에 따라 모델 구축 및 변수 설정을 하겠습니다.\n",
        "- 변수 설정\n",
        "  - 2-bar data -> T = 32\n",
        "  - 16-bar data -> T = 256\n",
        "  - 4-bar data -> T = 64가 됩니다.\n",
        "  - U = 16, 전체 입력 X는 16개의 서브시퀀스로 나뉘게 됩니다.\n",
        "  - Adam 을 사용했으며, lr_rate는 1e-3 ~ 1e-5 이며 exponential decay rate는 0.9999를 사용함\n",
        "  - batch_size는 512\n",
        "  - loss는 cross-entropy 사용\n",
        "  - 2-bar model and teacher forcing for 16-bar model\n",
        "\n",
        "- 기타 파라미터\n",
        "  - max_seq_len = 64 # 4마디 길이\n",
        "  - z_size = 512 # latent vector size\n",
        "  - slice_bars = 4 # 4마디"
      ],
      "metadata": {
        "id": "hd2SvvfEBVjv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "#def kl_divergence(p, q):\n",
        "  #return p*tf.math.log(p/q) + (1-p)*tf.math.log((1-p) / (1-q))\n",
        "\n",
        "def kl_divergence(p, q):\n",
        "    return np.sum(np.where(p != 0, p * np.log(p / q), 0))\n",
        "\n",
        "\n",
        "def sampling(inputs):\n",
        "  \"\"\"\n",
        "  return\n",
        "    z: latent vector\n",
        "  \"\"\"\n",
        "  z_mean, z_log_var = inputs\n",
        "  eps = tf.random.normal(tf.shape(z_log_var), dtype=tf.float32, mean=0., stddev=1.0, name='epsilon')\n",
        "  z = z_mean + tf.exp(z_log_var / 2) * eps\n",
        "  \n",
        "  return z\n",
        "\n"
      ],
      "metadata": {
        "id": "G6wUE1-gu8XS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_dim = 512\n",
        "latent_dim = 2\n",
        "num_feat = 1 ## data feature?\n",
        "batch_size = 32"
      ],
      "metadata": {
        "id": "yOhQIOlnu8Uw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# encoder\n",
        "inputs = keras.layers.Input(shape=(num_feat, ), name='midi')\n",
        "x = keras.layers.Dense(hidden_dim, activation='tanh')(inputs)\n",
        "z_mean = keras.layers.Dense(latent_dim, name='z_mean')(x)\n",
        "z_log_var = keras.layers.Dense(latent_dim, name='z_log_var')(x)"
      ],
      "metadata": {
        "id": "ESunAKn6u8SD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "z = keras.layers.Lambda(sampling, name='z')([z_mean, z_log_var])\n",
        "\n",
        "encoder = keras.Model(inputs, [z_mean, z_log_var, z], name='encoder')\n",
        "encoder.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sVCqL6Tzu8O2",
        "outputId": "7012e6ef-fc0c-4584-cc23-c1b06c90ada9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"encoder\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " midi (InputLayer)              [(None, 1)]          0           []                               \n",
            "                                                                                                  \n",
            " dense_32 (Dense)               (None, 512)          1024        ['midi[0][0]']                   \n",
            "                                                                                                  \n",
            " z_mean (Dense)                 (None, 2)            1026        ['dense_32[0][0]']               \n",
            "                                                                                                  \n",
            " z_log_var (Dense)              (None, 2)            1026        ['dense_32[0][0]']               \n",
            "                                                                                                  \n",
            " z (Lambda)                     (None, 2)            0           ['z_mean[0][0]',                 \n",
            "                                                                  'z_log_var[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 3,076\n",
            "Trainable params: 3,076\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# decoder \n",
        "\n",
        "latent_inputs = keras.layers.Input(shape=(latent_dim, ), name='z_sampling')\n",
        "x = keras.layers.Dense(hidden_dim, activation='tanh')(latent_inputs)\n",
        "outputs = keras.layers.Dense(num_feat, activation='tanh')(x)\n",
        "\n",
        "decoder = keras.Model(latent_inputs, outputs, name='decoder')\n",
        "decoder.summary()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pm0I4Y6gu8MJ",
        "outputId": "efb394e4-714d-4b71-dd0f-0afe85969186"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"decoder\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " z_sampling (InputLayer)     [(None, 2)]               0         \n",
            "                                                                 \n",
            " dense_33 (Dense)            (None, 512)               1536      \n",
            "                                                                 \n",
            " dense_34 (Dense)            (None, 1)                 513       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,049\n",
            "Trainable params: 2,049\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = decoder(encoder(inputs)[2])\n",
        "\n",
        "vae = keras.Model(inputs, outputs, name='vae')\n",
        "\n",
        "loss = tf.losses.binary_crossentropy(inputs, outputs)\n",
        "kl_loss = tf.losses.kl_divergence(inputs, outputs)\n",
        "vae.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IVGyP8Z8u8JG",
        "outputId": "555b743d-bebe-4df2-b49c-4b3e1e8cef55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"vae\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " midi (InputLayer)           [(None, 1)]               0         \n",
            "                                                                 \n",
            " encoder (Functional)        [(None, 2),               3076      \n",
            "                              (None, 2),                         \n",
            "                              (None, 2)]                         \n",
            "                                                                 \n",
            " decoder (Functional)        (None, 1)                 2049      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,125\n",
            "Trainable params: 5,125\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "vae.add_loss(kl_loss)\n",
        "vae.compile(optimizer='adam')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "ZC6_-nMEzpNr",
        "outputId": "e02b44d0-7eeb-43ee-8c69-6055ae4f4d87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-246-95cce6bb770e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mvae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkl_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mvae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36madd_loss\u001b[0;34m(self, losses, **kwargs)\u001b[0m\n\u001b[1;32m   1590\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0msymbolic_loss\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msymbolic_losses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1591\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_is_graph_network'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1592\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_network_add_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msymbolic_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1593\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1594\u001b[0m         \u001b[0;31m# Possible a loss was added in a Layer's `build`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py\u001b[0m in \u001b[0;36m_graph_network_add_loss\u001b[0;34m(self, symbolic_loss)\u001b[0m\n\u001b[1;32m    906\u001b[0m     \u001b[0mnew_nodes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madd_loss_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minbound_nodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m     \u001b[0mnew_layers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madd_loss_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 908\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_insert_layers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_layers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_nodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    909\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_graph_network_add_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maggregation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py\u001b[0m in \u001b[0;36m_insert_layers\u001b[0;34m(self, layers, relevant_nodes)\u001b[0m\n\u001b[1;32m    849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m     \u001b[0;31m# Insert layers and update other layer attrs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 851\u001b[0;31m     \u001b[0mlayer_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_tracked_trackables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    852\u001b[0m     \u001b[0mdeferred_layers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/data_structures.py\u001b[0m in \u001b[0;36m__hash__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    948\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__hash__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 949\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"unhashable type: 'DictWrapper'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    950\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__eq__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'DictWrapper'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vae.fit(train_dataset, epochs=1, batch_size=batch_size, validation_data=val_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 750
        },
        "id": "OPNCAs5VzpLC",
        "outputId": "9b7acac4-17df-4225-ce8b-0006729199d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:559: UserWarning: Input dict contained keys ['bpm', 'drummer', 'id', 'style', 'time_signature', 'type'] which did not match any model input. They will be ignored by the model.\n",
            "  inputs = self._flatten_to_reference_inputs(inputs)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "StagingError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mStagingError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-247-f9332289acc6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1146\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1147\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1148\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mStagingError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1010, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1000, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 859, in train_step\n        y_pred = self(x, training=True)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/node.py\", line 165, in map_arguments\n        flat_arguments[kt_index] = tensor_dict[kt_id].pop()\n\n    IndexError: Exception encountered when calling layer \"vae\" (type Functional).\n    \n    pop from empty list\n    \n    Call arguments received:\n      • inputs={'bpm': 'tf.Tensor(shape=(None,), dtype=int32)', 'drummer': 'tf.Tensor(shape=(None,), dtype=int64)', 'id': 'tf.Tensor(shape=(None,), dtype=string)', 'midi': 'tf.Tensor(shape=(None,), dtype=string)', 'style': {'primary': 'tf.Tensor(shape=(None,), dtype=int64)', 'secondary': 'tf.Tensor(shape=(None,), dtype=string)'}, 'time_signature': 'tf.Tensor(shape=(None,), dtype=int64)', 'type': 'tf.Tensor(shape=(None,), dtype=int64)'}\n      • training=True\n      • mask=None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PyTorch\n",
        "\n",
        "![](https://gaussian37.github.io/assets/img/dl/concept/vae/0.png)\n",
        "![](https://i.imgur.com/y397wfb.png)\n",
        "\n",
        "파이토치로 구현\n",
        "\n",
        "- Encoder\n",
        "  - mu:\n",
        "  - sigma:\n",
        "  - z:\n",
        "- Decoder\n",
        "  - x'\n",
        "\n",
        "- Condutor\n",
        "  - \n"
      ],
      "metadata": {
        "id": "6ML3Nu-eSMfV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### VAE with MNIST data"
      ],
      "metadata": {
        "id": "XN76OpTGsrDC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ykyTmSPvZYrV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from time import time\n",
        "import datetime\n",
        "import torch\n",
        "import torchvision\n",
        "from torch import nn\n",
        "import torch.optim as optim\n",
        "from torch.nn import functional as F\n",
        "\n",
        "from tqdm.auto import tqdm\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "current_time = datetime.datetime.now() + datetime.timedelta(hours=9) # 시차\n",
        "current_time = current_time.strftime('%Y-%m-%d-%H:%M')\n",
        "saved_loc = os.path.join('/drive/MyDrive/VAE_Result', current_time)\n",
        "os.makedirs(saved_loc)\n",
        "\n",
        "writer = SummaryWriter(saved_loc)\n",
        "EPOCHS = 50\n",
        "BATCH_SIZE = 200"
      ],
      "metadata": {
        "id": "nIXo-QJhWPHg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "VAE의 가장 핵심은 인코더-디코더 구조와 mu, sigma이다.\n",
        "\n",
        "먼저 인코더는 데이터를 받아와서 mu와 sigma를 출력해야 한다. 인코더는 데이터를 입력받아 hidden_size 만큼 출력하고, 이를 받아서 다시 latent_size 만큼의 mu와 sigma를 출력한다\n",
        "\n",
        "이 작업은 encode 함수를 통해 이루어진다.\n",
        "\n",
        "그 다음에는 reparameterization 과정이 필요하다. 만약 인코더의 결과물을 바로 디코더로 넘긴다면 어떻게 될까? 당연히 한 가지 값만 가지므로 그에대한 디코더 값 역시 한 값만 나오게 된다. 즉, 어떤 입력에 대해서 무조건 똑같은 output이 나오게 된다.\n",
        "\n",
        "하지만 VAE는 Generative 모델이다. 이는 곧 data의 분포를 가지고서 기존에 없는 새로운 data를 생성하고자 하는 것이다. 따라서 data의 분포를 샘플링 하되 reparmeterization을 적용한다.\n",
        "\n",
        "마지막으로 디코더 과정이다. self.decode(z)의 결과는 입력 데이터의 사이즈와 동일한 차원을 가지면서 sigmoid를 통과하므로 0~1 사이의 값을 갖게 된다. 이는 곧 input으로 투입한 데이터를 VAE를 거쳐 복원한 것이라고 볼 수 있다...\n",
        "\n",
        "\n",
        "출처: https://github.com/PeterKim1/paper_code_review"
      ],
      "metadata": {
        "id": "MS6tGm0pj8MT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.transforms as transforms\n",
        "# Transformer code\n",
        "transformer = transforms.Compose([\n",
        "            transforms.ToTensor()\n",
        "])\n",
        "\n",
        "# Loading trainset, testset and trainloader, testloader\n",
        "trainset = torchvision.datasets.MNIST(root = '/content/drive/MyDrive/MNIST', train = True,\n",
        "                                        download = True, transform = transformer)\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size = BATCH_SIZE, shuffle = True, num_workers = 2)\n",
        "\n",
        "\n",
        "testset = torchvision.datasets.MNIST(root = '/content/drive/MyDrive/MNIST', train = False,\n",
        "                                        download = True, transform = transformer)\n",
        "\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size = BATCH_SIZE, shuffle = True, num_workers = 2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423,
          "referenced_widgets": [
            "f5d5a5e24d374a07bf07f99f9d003ade",
            "e7403a799dfa47838ae1e9b1872253b8",
            "6017b73ec95447679622688ebc96acea",
            "300f3e7d72ca4bca8bbda20ef9268690",
            "102f9fcf15b34b019881fc63f83c3d74",
            "bcc23fb9bbe341209d787a8e7cb8c25a",
            "bdcc35d506a9452797480bb48b12bfe3",
            "a7e4103213d344d983470536e4cfb11d",
            "92127eb0246644e6b97bdd2e4483f393",
            "820bc15e02034cc781f4956122dccf77",
            "20d3e746a01d4675ac20ef23054692e7",
            "882a82f9f1d44db3b9b59709210b8ab7",
            "42bfdeef32724688a58b4277f62a96b2",
            "1869e2e54ee74d10a8bc80c218cea868",
            "04261721c30d4e27aae52ff39e83e3c6",
            "8193509dd6f04e5499fa0f5b6f6deaf0",
            "a99726ab30a342148d64b8bcd2837a75",
            "f4f76e46da1a48e5bfcc5e53adc75920",
            "20993d8cf88f4cce850d020196fd545b",
            "b58a10f4420c461fb6e5cb4535b05299",
            "a877a006554d4ab1848d225ce5d2cd6b",
            "8049b7fa308d4c928cac45480b63e5ed",
            "03190e4dbc9b4df68bcdcd1a49cb526f",
            "67d90e52600646c9b6591a63daf612ae",
            "a146eab698e447d2ac128d179a9e7ad3",
            "b2fb6d37f2b94233bdd08780271476ea",
            "5f85bbc07f3a4d9da2ab0b64b3f0b3e5",
            "0e10ac47b5b34a30a0e229b921bcc332",
            "03178f89e6f74128840df24073602570",
            "c99294ff22fc4bf9b132dcc188de9f60",
            "cddabab7347c41d6a1c2306a7a612a13",
            "dcfb86eeb9d04c689bf4270dfa2e7a56",
            "df4b0366a88b40078e773dc111e6a801",
            "ca4707a3f1eb4a0f8a932504ba0f52e9",
            "6bb95b80d3c743239abe414e742b4cab",
            "e17979f29d66452f8b78869505116eb5",
            "da4fc7f369934281987f1c7827bca7b4",
            "a1f0cbedae8a4f418d40fe6b179a9799",
            "c5cbc7a42acb483c9fe1b3aa78808297",
            "868c5b2f778a44c1b239bbb6009573d2",
            "23a7dfca1f0f417c88d4fca66b653997",
            "7fc6415dad2f42d9a0021e5d860d259f",
            "9aa340f8c35343fd9227ae8a310d134c",
            "8f285cb29c0449cda1e76713a6a3175f"
          ]
        },
        "id": "URsfct3iY2gR",
        "outputId": "0f1c89d6-bd97-464c-d3d0-ef1c9373edcb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to /content/drive/MyDrive/MNIST/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/9912422 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f5d5a5e24d374a07bf07f99f9d003ade"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /content/drive/MyDrive/MNIST/MNIST/raw/train-images-idx3-ubyte.gz to /content/drive/MyDrive/MNIST/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to /content/drive/MyDrive/MNIST/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/28881 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "882a82f9f1d44db3b9b59709210b8ab7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /content/drive/MyDrive/MNIST/MNIST/raw/train-labels-idx1-ubyte.gz to /content/drive/MyDrive/MNIST/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to /content/drive/MyDrive/MNIST/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1648877 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "03190e4dbc9b4df68bcdcd1a49cb526f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /content/drive/MyDrive/MNIST/MNIST/raw/t10k-images-idx3-ubyte.gz to /content/drive/MyDrive/MNIST/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to /content/drive/MyDrive/MNIST/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/4542 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ca4707a3f1eb4a0f8a932504ba0f52e9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /content/drive/MyDrive/MNIST/MNIST/raw/t10k-labels-idx1-ubyte.gz to /content/drive/MyDrive/MNIST/MNIST/raw\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sample check\n",
        "sample, label = next(iter(trainloader))\n",
        "\n",
        "# show grid image\n",
        "def imshow_grid(img):\n",
        "    img = torchvision.utils.make_grid(img)\n",
        "    print(type(img))\n",
        "    print(img.shape)\n",
        "    plt.imshow(img.permute(1, 2, 0))\n",
        "    ax = plt.gca()\n",
        "    ax.axes.xaxis.set_visible(False)\n",
        "    ax.axes.yaxis.set_visible(False)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "imshow_grid(sample[0:8])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 114
        },
        "id": "NTrR1fq5Y_1a",
        "outputId": "23fb79d8-b0fd-48b5-efea-40939599ec1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torch.Tensor'>\n",
            "torch.Size([3, 32, 242])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 부분"
      ],
      "metadata": {
        "id": "-z3Y96onZBiw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# VAE Model\n",
        "\n",
        "class VAE_Encoder(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, latent_size, output_size, num_layers=1, bidirectional=True):\n",
        "    \"\"\"\n",
        "    input_size: dim of input\n",
        "    hidden_size: LSTM hidden size\n",
        "    latent_size: dim of latent\n",
        "    num_layers: number of LSTM layers\n",
        "    bidirectional : \n",
        "    \"\"\"\n",
        "    super(VAE_Encoder, self).__init__()\n",
        "\n",
        "    if bidirectional == True:\n",
        "      num_directions = 2\n",
        "    else:\n",
        "      num_directions = 1\n",
        "    \n",
        "    # encoder\n",
        "\n",
        "    self.hidden_size = hidden_size\n",
        "    self.num_hidden = num_directions * num_layers\n",
        "    self.output_size = self.num_hidden * hidden_size\n",
        "\n",
        "    self.lstm = nn.LSTM(batch_first=True, # ?\n",
        "                        input_size=input_size,\n",
        "                        hidden_size=hidden_size,\n",
        "                        num_layers=num_layers,\n",
        "                        bidirectional=bidirectional)\n",
        "    \n",
        "    self.mu = nn.Linear(self.output_size, latent_size)\n",
        "    self.std = nn.Linear(self.output_size, latent_size)\n",
        "    self.norm = nn.LayerNorm(latent_size, elementwise_affine=False) # ?\n",
        "\n",
        "\n",
        "  def encode(self, x):\n",
        "    x, (h, c) = self.lstm(x)\n",
        "    h = h.transpose(0, 1).reshape(-1, self.output_size)\n",
        "\n",
        "    mu = self.norm(self.mu(h))\n",
        "    std = nn.Softplus()(self.std(h)) # ?\n",
        "\n",
        "    # reparam\n",
        "    z = self.reparam(mu, std)\n",
        "    \n",
        "    return z, mu, std\n",
        "\n",
        "\n",
        "  def reparam(self, mu, std):\n",
        "    eps = torch.randn_like(std)\n",
        "    # randn_like: input을 평균이 0, 분산이 1인 정규분포의 난수로 채워진 동일 크기 텐서 반환\n",
        "\n",
        "    return mu + (eps * std)\n",
        "\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    z, mu, std = self.encode(x)\n",
        "    return z, mu, std\n",
        "\n",
        "\n",
        "def vae_loss(recon_x, x, mu, std, beta=0):\n",
        "  logvar = std.pow(2).log()\n",
        "  BCE = F.binary_cross_entropy(recon_x, x, reduction='sum')\n",
        "  KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "\n",
        "  return BCE + (beta * KLD)\n",
        "\n",
        "def accuracy(y_true, y_pred):\n",
        "  y_ture = torch.argmax(y_true, axis=2)\n",
        "  total_num = y_true.shape[0] * y_true.shape[1]\n",
        "\n",
        "  return torch.sum(y_ture == y_pred) / total_num\n"
      ],
      "metadata": {
        "id": "m60kWYgeebrg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class VAE_Decoder(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, output_size, num_layers=2):\n",
        "    super(VAE_Decoder, self).__init__()\n",
        "\n",
        "    self.input_size = input_size\n",
        "    self.hidden_size = hidden_size\n",
        "    self.output_size = output_size\n",
        "    self.num_hidden = 1 * num_layers\n",
        "\n",
        "    self.logits = nn.Linear(hidden_size, output_size)\n",
        "    self.decoder = nn.LSTM(batch_first=True,\n",
        "                           input_size=input_size+output_size,\n",
        "                           hidden_size=hidden_size,\n",
        "                           num_layers=num_layers,\n",
        "                           bidirectional=False)\n",
        "  \n",
        "  def forward(self, x, h, c, temp=1):\n",
        "    \"\"\"\n",
        "    x: input seq\n",
        "    h: LSTM state (num_hidden, batch, hidden_size)\n",
        "    c: LSTM cell (num_hidden, batch, hidden_size)\n",
        "    temp: temperature of softmax\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    out: predicted label (bathc, 1, output_size)\n",
        "    prob: predicted prob( batch, 1, output_size)\n",
        "    h : next LSTM state\n",
        "    c : next LSTM cell\n",
        "    \"\"\"\n",
        "\n",
        "    x, (h, c) = self.decoder(x, (h, c))\n",
        "    logits = self.logits(x) / temp\n",
        "    prob = nn.Softmax(dim=2)(logits)\n",
        "    out = torch.argmax(prob, 2)\n",
        "\n",
        "    return out, prob, h, c\n",
        "\n",
        "    "
      ],
      "metadata": {
        "id": "y8mnTHmnbiWz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Conductor(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, num_layers=2, bidirectional=False, bar=4):\n",
        "    \"\"\"\n",
        "    input_size: input dim\n",
        "    hidden_size: dim of LSTM hidden size\n",
        "    output_size: dim of output seq\n",
        "    num_layers: number of LSTM layers\n",
        "    bar: number of units in bar\n",
        "    \"\"\"\n",
        "\n",
        "    super(Conductor, self).__init__()\n",
        "    self.bar = bar\n",
        "    \n",
        "    self.input_size = input_size\n",
        "    self.hidden_size = hidden_size\n",
        "    self.num_hidden = 1 * num_layers\n",
        "\n",
        "    self.norm = nn.BatchNorm1d(input_size)\n",
        "    self.linear = nn.Linear(hidden_size, hidden_size)\n",
        "    self.conductor = nn.LSTM(batch_first=True,\n",
        "                             input_size=input_size,\n",
        "                             hidden_size=hidden_size,\n",
        "                             num_layers=num_layers,\n",
        "                             bidirectional=bidirectional)\n",
        "    \n",
        "  def init_hidden(self, batch_size, z): # ??\n",
        "    h0 = z.repeat(self, num_hidden, 1, 1)\n",
        "    c0 = z.repeat(self, num_hidden, 1, 1)\n",
        "    return h0, c0\n",
        "\n",
        "  def forward(self, z):\n",
        "    \"\"\"\n",
        "    z: latent z (batch, input_size)\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    feat: conductor feat (batch, bar_seq, hidden_size)\n",
        "    \"\"\"\n",
        "\n",
        "    batch_size = z.shape[0]\n",
        "\n",
        "    z = self.norm(z) # ? paper와 다른 부분\n",
        "    h, c = self.init_hidden(batch_size, z)\n",
        "    z = z.unsqueeze(1) # ?\n",
        "\n",
        "    # initialize\n",
        "    feat = torch.zeors(batch_size, self.bar, self.hidden_size, device=device)\n",
        "\n",
        "    # conductor\n",
        "    z_input = z\n",
        "    for i in range(self.bar):\n",
        "      z_input, (h, c) = self.conductor(z_input, (h, c))\n",
        "      feat[:, i, :] = z_input.squeeze()\n",
        "      z_input = z\n",
        "    \n",
        "    feat = self.linear(feat)\n",
        "    return feat\n",
        "\n"
      ],
      "metadata": {
        "id": "bNpfaZXrc7KF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Hierarchical_Decoder(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, output_size, num_layers=2, bidirectional=False):\n",
        "    \"\"\"\n",
        "    \"\"\"\n",
        "    super(Hierarchical_Decoder, self).__init__()\n",
        "\n",
        "    if bidirectional == True:\n",
        "      num_directions = 2\n",
        "    else:\n",
        "      num_directions = 1\n",
        "    \n",
        "    self.input_size = input_size\n",
        "    self.hidden_size = hidden_size\n",
        "    self.output_size = output_size\n",
        "    self.num_hidden = num_directions * num_layers\n",
        "\n",
        "    self.logits = nn.Linear(hidden_size, output_size)\n",
        "    self.decoder = nn.LSTM(batch_first=True,\n",
        "                           input_size=input_size + output_size,\n",
        "                           hidden_size=hidden_size,\n",
        "                           num_layers=num_layers,\n",
        "                           bidirectional=bidirectional)\n",
        "  \n",
        "  def forward(self, x, h, c, z, temp=1):\n",
        "    \"\"\"\n",
        "    x: input seq (batch, 1, feat)\n",
        "    h: LSTM state (num_hidden, batch, hidden_size)\n",
        "    c: LSTM cell (num_hidden, batch, hidden_size)\n",
        "    z: latent feature\n",
        "    temp: temperature of softmax\n",
        "\n",
        "    RETURNs\n",
        "    ----------\n",
        "    out:\n",
        "    prob:\n",
        "    h:\n",
        "    c:\n",
        "    \"\"\"\n",
        "\n",
        "    x = torch.cat((x, z.unsqueeze(1)), 2) # ??\n",
        "\n",
        "    x, (h, c) = self.decoder(x, (h, c))\n",
        "    logits = self.logtis(x) / temp\n",
        "    prob = nn.Softmax(dim=2)(logits)\n",
        "    out = torch.argmax(prob, 2)\n",
        "\n",
        "    return out, prob, h, c"
      ],
      "metadata": {
        "id": "A7oyPc4Tc7DK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def inverse_sigmoid(epoch, k=20):\n",
        "    return k / (k + np.exp(epoch/k))\n",
        "\n",
        "def kl_annealing(epoch, start, end, rate=0.9):\n",
        "    return end + (start - end)*(rate)**epoch"
      ],
      "metadata": {
        "id": "Wj5MAccdc6_n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def flat_train(loss_fn, train_loader, val_loader, model, optimizer, temp=1, epochs=100):\n",
        "  history = {}\n",
        "  history['train_loss'] = []\n",
        "  history['train_acc'] = []\n",
        "  history['val_loss'] = []\n",
        "  history['val_acc'] = []\n",
        "\n",
        "  encoder, decoder = model\n",
        "  enc_optim, dec_optim = optimizer\n",
        "\n",
        "  hidden_size = decoder.hidden_size\n",
        "  num_hidden = decoder.num_hidden\n",
        "  output_size = decoder.output_size\n",
        "\n",
        "  enc_sch = optim.lr_scheduler.CosineAnnealingLR(enc_optim, epochs, eta_min=1e-6) #?\n",
        "  dec_sch = optim.lr_scheduler.CosineAnnealingLR(dec_optim, epochs, eta_min=1e-6)\n",
        "\n",
        "  for i in range(1, epochs+1):\n",
        "    st = time()\n",
        "    train_loss = 0\n",
        "    train_acc = 0\n",
        "    val_loss = 0\n",
        "    val_acc = 0\n",
        "\n",
        "    encoder.train()\n",
        "    decoder.train()\n",
        "\n",
        "    for batch_idx, x_train in enumerate(train_loader):\n",
        "      x_train = x_train.to(device)\n",
        "\n",
        "      batch_size = x_train.shape[0]\n",
        "      seq_len = x_train.shape[1]\n",
        "\n",
        "      enc_optim.zero_grad()\n",
        "      dec_optim.zero_grad()\n",
        "\n",
        "      # encoder\n",
        "      z, x_train_mu, x_train_std = encoder(x_train)\n",
        "\n",
        "      h = z.repeat(num_hidden, 1, int(hidden_size/z.shape[1]))\n",
        "      c = z.repeat(num_hidden, 1, int(hidden_size/z.shape[1]))\n",
        "\n",
        "      x_train_inputs = torch.zeros((batch_size, 1, x_train.shape[2]), device=device)\n",
        "      x_train_inputs = torch.cat((x_train_inputs, z.unsqueeze(1)), 2)\n",
        "      x_train_label = torch.zeros(x_train.shape[:-1], device=device) # argmax\n",
        "      x_train_prob = torch.zeros(x_train.shape, device=device) # prob\n",
        "\n",
        "      # forward\n",
        "      for j in range(seq_len):\n",
        "        label, prob, h, c = decoder(x_train_inputs, h, c, temp=1)\n",
        "\n",
        "        x_train_label[:, j] = label.squeeze()\n",
        "        x_train_prob[:, j, :] = prob.squeeze()\n",
        "\n",
        "        # scheduled sampling\n",
        "        if np.random.binomial(1, inverse_sigmoid(i)): # ???\n",
        "          # teacher forcing ?\n",
        "          x_train_inputs = torch.cat((x_train[:, j, :], z), 1).unsqueeze(1)\n",
        "        else:\n",
        "          # sampling\n",
        "          label = F.one_hot(label, num_classes=output_size)\n",
        "          x_train_inputs = torch.cat((label, z.unsqueeze(1)), 2)\n",
        "      \n",
        "      # loss\n",
        "      beta = kl_annealing(i, 0, 0.2)\n",
        "      loss = loss_fn(x_train_prob, x_train, x_train_mu, x_train_std, beta)\n",
        "\n",
        "      # backward\n",
        "      loss.backward()\n",
        "      enc_optim.step()\n",
        "      dec_optim.step()\n",
        "\n",
        "      train_loss += loss.item()\n",
        "      train_acc += accuracy(x_train, x_train_label).item()\n",
        "\n",
        "    enc_sch.step()\n",
        "    dec_sch.step()\n",
        "\n",
        "    train_loss = train_loss / (batch_idx + 1)\n",
        "    train_acc = train_acc / (batch_idx + 1)\n",
        "\n",
        "    history['train_loss'].append(train_loss)\n",
        "    history['traina_acc'].append(train_acc)\n",
        "\n",
        "    ### validation\n",
        "    encoder.eval()\n",
        "    decoder.eval()\n",
        "    with torch.no_grad():\n",
        "      for batch_idx, x_val in enumerate(val_loader):\n",
        "        x_val = x_val.to(device)\n",
        "\n",
        "        batch_size = x_val.shape[0]\n",
        "        seq_len = x_val.shape[1]\n",
        "\n",
        "        # forward encoder\n",
        "        z, x_val_mu, x_val_std = encoder(x_val)\n",
        "\n",
        "        # initialize\n",
        "        h = z.repeat(num_hidden, 1, int(hidden_size / z.shape[1]))\n",
        "        c = z.repeat(num_hidden, 1, int(hidden_size / z.shape[1]))\n",
        "\n",
        "        # full sampling\n",
        "        x_val_inputs = torch.zeros((batch_size, 1, x_val.shape[2]), device=device)\n",
        "        x_val_inputs = torch.cat((x_val_inputs, z.unsqueeze(1)), 2)\n",
        "        x_val_label = torch.zeros(x_val.shape[:-1], device=device)\n",
        "        x_val_prob = torch.zeros(x_val.shape, device=device)\n",
        "\n",
        "        # forward\n",
        "        for j in range(seq_len):\n",
        "          label, prob, h, c = decoder(x_val_inputs, h, c, temp=1)\n",
        "\n",
        "          x_val_label[:, j] = label.squeeze()\n",
        "          x_val_prob[:, j, :] = prob.squeeze()\n",
        "\n",
        "          label = F.one_hot(label, num_classes=output_size)\n",
        "          x_val_inputs = torch.cat((label, z.unsqueeze(1)), 2)\n",
        "\n",
        "        loss = loss_fn(x_val_prob, x_val, x_val_mu, x_val_std, beta)\n",
        "\n",
        "        val_loss += loss.item()\n",
        "        val_acc += accuracy(x_val, x_val_label).item()\n",
        "\n",
        "    val_loss = val_loss / (batch_idx + 1)\n",
        "    val_acc = val_acc / (batch_idx + 1)\n",
        "\n",
        "    history['val_loss'].append(val_loss)\n",
        "    history['val_acc'].append(val_acc)\n",
        "\n",
        "    print('Epoch %d (%0.2f sec) - train_loss: %0.3f, train_acc: %0.3f, val_loss: %0.3f, val_acc: %0.3f, lr: %0.6f' % \\\n",
        "             (i, time()-st, train_loss, train_acc, val_loss, val_acc, enc_sch.get_last_lr()[0]))\n",
        "    \n",
        "    return history\n",
        "\n"
      ],
      "metadata": {
        "id": "Q4gXIOdCgGT3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "yZ3qClxcNajI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Drum <-> Numpy"
      ],
      "metadata": {
        "id": "qSDPX4ZmLh4N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pretty_midi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X8N9YAluLqtW",
        "outputId": "b7d2ce63-65a4-4b1b-9f8d-0cdd0a1abc72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pretty_midi\n",
            "  Downloading pretty_midi-0.2.9.tar.gz (5.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.6 MB 4.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from pretty_midi) (1.21.6)\n",
            "Collecting mido>=1.1.16\n",
            "  Downloading mido-1.2.10-py2.py3-none-any.whl (51 kB)\n",
            "\u001b[K     |████████████████████████████████| 51 kB 8.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from pretty_midi) (1.15.0)\n",
            "Building wheels for collected packages: pretty-midi\n",
            "  Building wheel for pretty-midi (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pretty-midi: filename=pretty_midi-0.2.9-py3-none-any.whl size=5591955 sha256=c75765a104fc7b964f5dcf98f04b3d3ea165eb18bfcabc45bb7484a0d843bfe8\n",
            "  Stored in directory: /root/.cache/pip/wheels/ad/74/7c/a06473ca8dcb63efb98c1e67667ce39d52100f837835ea18fa\n",
            "Successfully built pretty-midi\n",
            "Installing collected packages: mido, pretty-midi\n",
            "Successfully installed mido-1.2.10 pretty-midi-0.2.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pretty_midi\n",
        "\n",
        "def drum_play(array, fs, comp=9):\n",
        "    \"\"\"Convert numpy object to pretty_midi \n",
        "     \n",
        "    Parameters\n",
        "    ----------\n",
        "    array : numpy array (seq, feat)\n",
        "    fs : sampling rate that you intended\n",
        "    comp : the number of drum components\n",
        "    Returns\n",
        "    -------\n",
        "    pm : pretty_midi object\n",
        "    \"\"\"\n",
        "        \n",
        "    fs_time = 1 / fs\n",
        "    \n",
        "    standard, encoded = get_comp()\n",
        "    reverse_standard = {v: k for k, v in standard.items()}\n",
        "    reverse_encoded = {v: k for k, v in encoded.items()}\n",
        "    \n",
        "    decimal_idx= np.where(array == 1)[1]\n",
        "    binary_idx = list(map(lambda x: np.binary_repr(x, comp), decimal_idx))\n",
        "    \n",
        "    # initialize\n",
        "    pm = pretty_midi.PrettyMIDI()\n",
        "    inst = pretty_midi.Instrument(program=32, is_drum=True)\n",
        "    pm.instruments.append(inst)\n",
        "    \n",
        "    for i, inst_in_click in enumerate(binary_idx):\n",
        "        start_time = fs_time * i\n",
        "        end_time = fs_time * (i + 1)\n",
        "        \n",
        "        # add instruments\n",
        "        for j in range(0, len(inst_in_click)):\n",
        "            if inst_in_click[j] == '1':\n",
        "                pitch = reverse_standard[reverse_encoded[j]]\n",
        "                inst.notes.append(pretty_midi.Note(80, pitch, start_time, end_time))\n",
        "                \n",
        "    return "
      ],
      "metadata": {
        "id": "D6ldyGYQLkuN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### MusicVAE flat"
      ],
      "metadata": {
        "id": "yL1Mb8nlLTtZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/drive/Mydrive/'"
      ],
      "metadata": {
        "id": "NBIsoqInLPth"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "squeeze 함수\n",
        "- 차원이 1인 차원을 제거한다. 따로 설정하지 않으면 1인 차원을 모두 제거함. 차원 설정 시 해당 차원만 제거함\n",
        "- 주의점: batch가 1인 경우 batch 차원도 없애버릴 수 있으니, validation 단계에서 오류가 날 수 있음. 주의해서 사용\n",
        "\n",
        "unsqueeze 함수\n",
        "- squeeze와는 달리 1인 차원을 생성함. 어느 차원에 1인 차원을 생성할지 꼭 지정해야 함\n"
      ],
      "metadata": {
        "id": "mYCF_JPx4vjw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "x1 = torch.rand(3, 1, 20, 128)\n",
        "x1 = x1.squeeze()\n",
        "\n",
        "x2 = torch.rand(1, 20, 1, 128)\n",
        "x2 = x2.squeeze(dim=2)\n",
        "\n",
        "print(x1.shape, x2.shape)\n",
        "\n",
        "x = torch.rand(3, 20, 128)\n",
        "x = x.unsqueeze(dim=1)\n",
        "print(x.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x3so5wp2gGNz",
        "outputId": "19b3289c-370d-4e88-ea85-9f82b725a47b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 20, 128]) torch.Size([1, 20, 128])\n",
            "torch.Size([3, 1, 20, 128])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "DA-AWY4agGLO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Lf0AvY0cgGIa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def train(epoch, model, train_loader, optimizer):\n",
        "  model.train()\n",
        "  train_loss = 0\n",
        "  for bat_idx, (data, _) in enumerate(train_loader): # 라벨이 필요가 없음 _\n",
        "    data = data.to(device)\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    recon_batch, mu, logvar = model(data)\n",
        "\n",
        "    BCE, KLD = loss_function(recon_batch, data, mu, logvar)\n",
        "    loss = BCE + KLD\n",
        "\n",
        "    writer.add_scalar(\"Train/Reconstruction Error\", BCE.item(), bat_idx + epoch * (len(train_loader.dataset)/BATCH_SIZE) )\n",
        "    writer.add_scalar(\"Train/KL-Divergence\", KLD.item(), bat_idx + epoch * (len(train_loader.dataset)/BATCH_SIZE) )\n",
        "    writer.add_scalar(\"Train/Total Loss\" , loss.item(), bat_idx + epoch * (len(train_loader.dataset)/BATCH_SIZE) )\n",
        "\n",
        "\n",
        "    loss.backward()\n",
        "    train_loss += loss.item()\n",
        "    optimizer.step()\n",
        "\n",
        "    if bat_idx % 100 == 0:\n",
        "      print('Train epo: {} [{}/{} ({:.0f}%)]\\t Loss: {:.6f}'.format(\n",
        "          epoch, bat_idx * len(data), len(train_loader.dataset),\n",
        "          100. * bat_idx / len(train_loader),\n",
        "          loss.item() / len(data)\n",
        "          ))\n",
        "    \n",
        "  print('===========> Epoch: {} Avg loss: {:.4f}'.format(\n",
        "      epoch, train_loss / len(train_loader.dataset)\n",
        "  ))"
      ],
      "metadata": {
        "id": "RBs6cHgSecTi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_size = 784\n",
        "VAE_model = VAE(input_size, 512, 2).to(device)\n",
        "optimizer = optim.Adam(VAE_model.parameters(), lr=1e-3)"
      ],
      "metadata": {
        "id": "zbxpdl37ecWz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(epoch, model, test_loader):\n",
        "  model.eval()\n",
        "  test_loss = 0\n",
        "  with torch.no_grad():\n",
        "    for bat_idx, (data, _) in enumerate(test_loader):\n",
        "      data = data.to(device)\n",
        "\n",
        "      recon_batch, mu, logvar = model(data)\n",
        "      BCE, KLD = loss_function(recon_batch, data, mu, logvar)\n",
        "\n",
        "      loss = BCE + KLD\n",
        "\n",
        "      writer.add_scalar(\"Test/Reconstruction Error\", BCE.item(), bat_idx + epoch * (len(test_loader.dataset)/BATCH_SIZE) )\n",
        "      writer.add_scalar(\"Test/KL-Divergence\", KLD.item(), bat_idx + epoch * (len(test_loader.dataset)/BATCH_SIZE) )\n",
        "      writer.add_scalar(\"Test/Total Loss\" , loss.item(), bat_idx + epoch * (len(test_loader.dataset)/BATCH_SIZE) )\n",
        "\n",
        "      test_loss += loss.item()\n",
        "\n",
        "      if bat_idx == 0:\n",
        "        n = min(data.size(0), 8) # test_loader 데이터 8개와 이를 VAE를 거쳐 뽑은 reconstruction 결과 8개와 합친다 -> 16, 1, 28, 28\n",
        "        comparison = torch.cat([data[:n], recon_batch.view(BATCH_SIZE, 1, 28, 28)[:n]]) # (16, 1, 28, 28)\n",
        "        grid = torchvision.utils.make_grid(comparison.cpu()) # (3, 62, 242)\n",
        "        writer.add_image('Test image - Above: Realdata, below: reconstruction data', grid, epoch) # tensorboard\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "GUfxMmYuecQY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def latent_to_image(epoch, model):\n",
        "  # latent를 이미지로 변환\n",
        "  with torch.no_grad():\n",
        "    sample = torch.randn(64, 2).to(device) # 랜덤 값 생성 (평균0, 분산1 가우시안 분포)\n",
        "    recon_image = model.decode(sample).cpu() # decode를 통해 reconstruction 이미지 생성\n",
        "    grid = torchvision.utils.make_grid(recon_image.view(64, 1, 28, 28))\n",
        "    writer.add_image('Latent to Image', grid, epoch)"
      ],
      "metadata": {
        "id": "ZsuH6F6xmQ-4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습 진행\n",
        "for epoch in tqdm(range(0, EPOCHS)):\n",
        "  train(epoch, VAE_model, trainloader, optimizer)\n",
        "  test(epoch, VAE_model, testloader)\n",
        "  print()\n",
        "  latent_to_image(epoch, VAE_model)\n",
        "\n",
        "writer.close()"
      ],
      "metadata": {
        "id": "dHePilsrmQxV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir='/content/drive/MyDrive/VAE_Result'"
      ],
      "metadata": {
        "id": "A6yQubRbmQwU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "p0rJ9t2rq99x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "taQETyFFq96b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "dgVVaP3Jq93w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ZDhPseTLq905"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## VAE with music midi"
      ],
      "metadata": {
        "id": "HxfjKyn3sxm6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, latent_dim):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.hidden_size = hidden_size\n",
        "    self.num_hidden = 2*2\n",
        "    self.final_size = self.num_hidden * hidden_size\n",
        "\n",
        "    self.lstm = nn.LSTM(batch_first=True,\n",
        "                        input_size=input_size,\n",
        "                        hidden_size=hidden_size,\n",
        "                        num_layers=2,\n",
        "                        bidirectional=True)\n",
        "    \n",
        "    self.mu = nn.Linear(self.final_size, latent_dim)\n",
        "    self.sigma = nn.Linear(self.final_size, latent_dim)\n",
        "    self.z = nn.Linear(self.final_size, )\n",
        "  \n",
        "  def encode(self, x):\n",
        "    x, (hidden, cells) = self.lstm(x)\n",
        "    hidden = hidden.transpose(0, 1).reshape(-1, self.final_size)\n",
        "\n",
        "    mu = \n",
        "    sigma = \n",
        "\n",
        "    return z, mu, sigma\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 135
        },
        "id": "dJP8WNDjzpIQ",
        "outputId": "7b245daa-1c47-4dd7-9639-70e33dff9105"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-56-e6b9ad53230a>\"\u001b[0;36m, line \u001b[0;32m22\u001b[0m\n\u001b[0;31m    mu =\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Conductor(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size):\n",
        "    super(Conductor, self).__init__()\n",
        "    self.input_size = input_size\n",
        "    self.hidden_size = hidden_size\n",
        "    self.num_hidden = 2\n",
        "    self.bar = 4\n",
        "\n",
        "    self.lstm = nn.LSTM(batch_first=True,\n",
        "                        input_size=input_size,\n",
        "                        hidden_size=hidden_size,\n",
        "                        num_layers=1,)\n",
        "    \n",
        "    def forward(self, x):\n",
        "      pass\n",
        "      return a, b\n",
        "    \n",
        "\n"
      ],
      "metadata": {
        "id": "uHT-VPyJWR0o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, output_size):\n",
        "    super(Decoder, self).__init__()\n",
        "\n",
        "    self.input_size = input_size\n",
        "    self.hidden_size=hidden_size\n",
        "    self.output_size=output_size\n",
        "    self.lstm = nn.LSTM(batch_first=True,\n",
        "                        input_size=input_size+output_size,\n",
        "                        hidden_size=hidden_size,\n",
        "                        bidirectional=False)\n",
        "    self.logits = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def decode(self, x, hidden, cells):\n",
        "      x, (hidden, cells) = self.lstm(x, (hidden, cells))\n",
        "      logits = self.logits(x)\n",
        "      prob = nn.Softmax()(logits)\n",
        "      output = torch.argmax(prob)\n",
        "      \n",
        "      return output, prob, hidden, cells"
      ],
      "metadata": {
        "id": "6LnDrnVDzpFa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# magenta 활용\n",
        "\n",
        "magenta 라이브러리를 이용하여 다른 데이터셋으로 musicVAE를 학습할 수 있다.\n",
        "\n",
        "[참고링크](https://github.com/magenta/magenta/tree/main/magenta/models/music_vae)"
      ],
      "metadata": {
        "id": "7zAZD3rHA0UR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q magenta"
      ],
      "metadata": {
        "id": "3pM6jtsrBEjy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!curl https://raw.githubusercontent.com/tensorflow/magenta/main/magenta/tools/magenta-install.sh > /tmp/magenta-install.sh\n",
        "!bash /tmp/magenta-install.sh"
      ],
      "metadata": {
        "id": "KmA-vslkBDGT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "MyDrive/musicVAE/data 폴더에 groove MIDI [데이터셋](https://magenta.tensorflow.org/datasets/groove#midi-data)을 압축 해제하고 사용합니다."
      ],
      "metadata": {
        "id": "gS5KBpD6BnK-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!convert_dir_to_note_sequences --input_dir='/content/drive/MyDrive/musicVAE/data' --output_file=notesequences.tfrecord --recursive"
      ],
      "metadata": {
        "id": "0BeZPJm3BhcH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!music_vae_train --config=groovae_4bar --run_dir=music_vae/ --num_steps=2000 --mode=train --examples_path=notesequences.tfrecord \\\n",
        "--hparams=max_seq_len=64, z_size=512, batch_size=32, learning_rate=0.0005"
      ],
      "metadata": {
        "id": "bF9jggW5A0Lu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!music_vae_generate --config=groovae_4bar --checkpoint_file=music_vae/train --mode=sample --num_output=5 --output_dir=music_vae/generated"
      ],
      "metadata": {
        "id": "F70LwdooA0Dy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}